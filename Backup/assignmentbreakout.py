# -*- coding: utf-8 -*-
"""AssignmentBreakOut.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cvpj4XyRrFkimzKtB06mpHg2VqfRYCVa
"""

import pandas as pd
import os

print("Choose input method:")
print("1: Upload a CSV file")
print("2: Enter a Google Sheets link")
choice = input("Enter choice (1 or 2): ")

def load_csv():
    from google.colab import files
    uploaded = files.upload()
    filename = list(uploaded.keys())[0]
    df = pd.read_csv(filename)
    return df

def load_google_sheet(sheet_url):
    try:
        import re
        sheet_id = re.search('/spreadsheets/d/([a-zA-Z0-9-_]+)', sheet_url).group(1)

        csv_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv"
        df = pd.read_csv(csv_url)
        return df
    except (AttributeError, IndexError):
        print("Error: Invalid Google Sheets URL format.")
        return None

if choice == '1':
    df = load_csv()
elif choice == '2':
    sheet_url = input("Enter the Google Sheets link: ")
    df = load_google_sheet(sheet_url)
else:
    print("Invalid choice.")
    df = None

"""https://docs.google.com/spreadsheets/d/1wz3iIdlipf2GA1HcAbsX-kHjz01iRnxuJgzTRk87J3w/edit?usp=sharing

"""

if df is not None:
    print("First few rows of the dataset:")
    print(df.head())

if df is not None:
    print("\nDataset Information:")
    print(df.info())

print("\nAvailable columns:")
for i, col in enumerate(df.columns):
    print(f"{i + 1}: {col}")

col_choice = int(input("Select a column by number: ")) - 1

if 0 <= col_choice < len(df.columns):
    selected_attribute = df.columns[col_choice]
    print(f"\nYou selected: {selected_attribute}")
else:
    print("Invalid column selection.")

if selected_attribute:
    prompt = input("Enter a prompt, Note: You should enclosed the value of column in curly brackets{}.")

print(prompt)


from dotenv import load_dotenv
load_dotenv()

serpApi = os.getenv("serpApi")

import re
from serpapi import GoogleSearch

match = re.search(r'\{(.+?)\}', prompt)
selected_value = match.group(1)

def searchGoogle(prompt):
    # match = re.search(r'\{(.+?)\}', prompt)
    if not match:
        return "No value found in curly braces in the prompt."

    # selected_value = match.group(1)
    search_query = prompt.replace(f"For {{{selected_value}}}", str(df[selected_attribute].iloc[0]))
    # print(f"Search Query: {search_query}")

    params = {
        "engine": "google",
        "q": search_query,
        "api_key": serpApi
    }

    search = GoogleSearch(params)
    results = search.get_dict()

    if "organic_results" not in results or not results["organic_results"]:
        return "No search results found."


    formatted_results = []
    for result in results.get("organic_results", []):
        title = result.get("title", "No Title")
        link = result.get("link", "No Link")
        snippet = result.get("snippet", "No Snippet")
        formatted_results.append({
            "title": title.strip(),
            "link": link.strip(),
            "snippet": snippet.strip()
        })

    return formatted_results

import requests

GroqAPi = os.getenv("groqApi")



from groq import Groq


client = Groq(api_key=GroqAPi)


chat_history = [
    {
        "role": "system",
        "content": "You are an assistant specialized in extracting specific information from web pages based on a query. Provide only the requested information. If no relevant data is available, respond with 'Result not found' only and only."
    }
]


mapping = {}


def getResult(results, backPrompt, chat_history):
    """
    Extract and present information in a structured and concise format.
    """
    MAX_HISTORY_LENGTH = 5
    chat_history = chat_history[-MAX_HISTORY_LENGTH:]

    all_responses = []
    organic_results = results

    for batch in organic_results:
        # Formulate user query for Groq
        chat_history.append({
            "role": "user",
            "content": f"""
            I have a search result. Please extract the requested details:

            Search Result:
            Title: {batch['title']}
            Link: {batch['link']}
            Snippet: {batch['snippet']}

            Extraction Task:
            {backPrompt}

            Provide only the requested information.
            """
        })

        # Send request to Groq
        completion = client.chat.completions.create(
            model="llama3-8b-8192",
            messages=chat_history
        )

        ai_response = completion.choices[0].message.content
        chat_history.append({
            "role": "assistant",
            "content": ai_response
        })

        # Consolidate responses
        if "result not found" not in ai_response.lower():
            all_responses.append(ai_response)

    if not all_responses:
        return "Result not found."

    # Format responses into a single output
    # return "\n".join(all_responses)
    return combineResponses(all_responses)


def combineResponses(responses):
    """
    Dynamically aggregate and deduplicate responses into a single coherent response.
    """
    unique_responses = set(responses)  # Remove duplicates
    combined_response = "\n".join(unique_responses)

    # Additional formatting (if required)
    result = f"**Extracted Information:**\n{combined_response}"
    return result.strip()


while True:
    backPrompt = input(f"Enter the details you want to fetch about the selected attribute: ('0' to end) ")
    if backPrompt == '0':
        break

    search_results = searchGoogle(prompt)
    aiResponse = getResult(search_results, backPrompt, chat_history)
    print("Extracted Information:")
    print(aiResponse)
    print('\n\n')
    mapping[backPrompt] = aiResponse
    # print(mapping)
    print('\n\n')

import pandas as pd

# File path for the results file
file_path = "results.csv"

# Prepare data for appending
data = {"User Query": [], "AI Response": []}
for query, response in mapping.items():
    data["User Query"].append(query)
    data["AI Response"].append(response)

# Convert mapping to DataFrame
df = pd.DataFrame(data)

try:
    # Append to existing file if it exists
    existing_df = pd.read_csv(file_path)
    updated_df = pd.concat([existing_df, df], ignore_index=True)
    updated_df.to_csv(file_path, index=False)
except FileNotFoundError:
    # Create new file if it doesn't exist
    df.to_csv(file_path, index=False)

print(f"Results file created or updated at {file_path}.")

# Ask for confirmation before opening the file
download_confirmation = input("Are you satisfied with the results and want to open the file? (yes/no): ")

if download_confirmation.lower() == "yes":
    import os
    os.startfile(file_path)
else:
    print("Operation cancelled.")